{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3347e0fa-4825-4701-9c91-4b08c75fd56f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from human_eval.data import write_jsonl, read_problems, extract_python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4fa3c5f1-2d7a-49c2-85d0-2a4846b900f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Here is the complete code:\\n```python\\nimport ...\n",
       "1      Plan:\\n\\n1. Import the necessary libraries for...\n",
       "2      [PYTHON]\\nimport numpy as np\\nfrom skimage imp...\n",
       "3      Here is a possible implementation of the bland...\n",
       "4      Here's the code for the function `combine_colu...\n",
       "                             ...                        \n",
       "565    Here is the complete code for the function `wo...\n",
       "566    Plan:\\n\\n1. Convert the input image to graysca...\n",
       "567    Here is the complete code for the function `wo...\n",
       "568    ```python\\nimport numpy as np\\nimport pandas a...\n",
       "569    Here is the complete code for the function `wo...\n",
       "Name: full_response, Length: 570, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_json(\"data/samples_codellama.jsonl\", lines=True)\n",
    "df[\"full_response\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7251bbad-8ae8-42f9-ac0d-a46f01b6d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = \"data/\"\n",
    "\n",
    "collection = []\n",
    "for filename in os.listdir(directory):\n",
    "    jsonl_file = filename.endswith(\".jsonl\") and not filename.endswith(\"results.jsonl\") and not filename.endswith(\"bia.jsonl\")\n",
    "    results_jsonl_file = filename.endswith(\"_results.jsonl\")\n",
    "    if jsonl_file:\n",
    "        df = pd.read_json(directory + filename, lines=True)\n",
    "        df['model'] = filename.replace(\".jsonl\", \"\").replace(\"samples_\", \"\")\n",
    "        collection.append(df)\n",
    "    # if results_jsonl_file:\n",
    "    #     df = pd.read_json(directory + filename, lines=True)\n",
    "    #     df['model'] = filename.replace(\"_results.jsonl\", \"\").replace(\"samples_\", \"\")\n",
    "    #     collection.append(df)\n",
    "\n",
    "df = pd.concat(collection)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1b17733a-dbc0-4c76-a80a-e6214dfa7ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>task_id</th>\n",
       "      <th>completion</th>\n",
       "      <th>full_response</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../test_cases/apply_otsu_threshold_and_count_p...</td>\n",
       "      <td>\\n# 1. Import necessary libraries: OpenCV for ...</td>\n",
       "      <td>Here is the completed code with comments on ho...</td>\n",
       "      <td>llama3-8b-instruct-fp16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../test_cases/binary_closing.ipynb</td>\n",
       "      <td>\\nimport cv2\\nfrom skimage import filters, mea...</td>\n",
       "      <td>Here is the plan as comments:\\n\\n# Plan:\\n# 1....</td>\n",
       "      <td>llama3-8b-instruct-fp16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../test_cases/binary_skeleton.ipynb</td>\n",
       "      <td>Python\\n# Plan:\\n# 1. Import necessary librari...</td>\n",
       "      <td>Here is the complete code:\\n\\n```Python\\n# Pla...</td>\n",
       "      <td>llama3-8b-instruct-fp16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../test_cases/bland_altman.ipynb</td>\n",
       "      <td>\\n# Plan:\\n# 1. Check if the input dataframe a...</td>\n",
       "      <td>Here is the complete code:\\n\\n```python\\n# Pla...</td>\n",
       "      <td>llama3-8b-instruct-fp16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../test_cases/combine_columns_of_tables.ipynb</td>\n",
       "      <td>\\n# Plan:\\n# 1. Check if index column exists i...</td>\n",
       "      <td>Here is the complete code:\\n\\n```python\\n# Pla...</td>\n",
       "      <td>llama3-8b-instruct-fp16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>../test_cases/workflow_batch_process_folder_me...</td>\n",
       "      <td>1. Import the necessary libraries that will be...</td>\n",
       "      <td>1. Import the necessary libraries that will be...</td>\n",
       "      <td>codellama-70b-instruct-q4_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>../test_cases/workflow_segmentation_counting.i...</td>\n",
       "      <td>\\nimport numpy as np # For working with arrays...</td>\n",
       "      <td>1. Import the necessary Python libraries:\\n\\n`...</td>\n",
       "      <td>codellama-70b-instruct-q4_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>../test_cases/workflow_segmentation_measuremen...</td>\n",
       "      <td>\\nimport cv2  # For thresholding and image pro...</td>\n",
       "      <td>1. **Thresholding**: Using Otsu's thresholding...</td>\n",
       "      <td>codellama-70b-instruct-q4_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>../test_cases/workflow_segment_measure_umap.ipynb</td>\n",
       "      <td>\\nimport numpy as np\\nfrom skimage import io, ...</td>\n",
       "      <td>```python\\nimport numpy as np\\nfrom skimage im...</td>\n",
       "      <td>codellama-70b-instruct-q4_0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>569</th>\n",
       "      <td>../test_cases/workflow_watershed_segmentation_...</td>\n",
       "      <td>\\nimport numpy as np\\nfrom sklearn.cluster imp...</td>\n",
       "      <td>1. Blurring and local minimas detection:\\n    ...</td>\n",
       "      <td>codellama-70b-instruct-q4_0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11400 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               task_id  \\\n",
       "0    ../test_cases/apply_otsu_threshold_and_count_p...   \n",
       "1                   ../test_cases/binary_closing.ipynb   \n",
       "2                  ../test_cases/binary_skeleton.ipynb   \n",
       "3                     ../test_cases/bland_altman.ipynb   \n",
       "4        ../test_cases/combine_columns_of_tables.ipynb   \n",
       "..                                                 ...   \n",
       "565  ../test_cases/workflow_batch_process_folder_me...   \n",
       "566  ../test_cases/workflow_segmentation_counting.i...   \n",
       "567  ../test_cases/workflow_segmentation_measuremen...   \n",
       "568  ../test_cases/workflow_segment_measure_umap.ipynb   \n",
       "569  ../test_cases/workflow_watershed_segmentation_...   \n",
       "\n",
       "                                            completion  \\\n",
       "0    \\n# 1. Import necessary libraries: OpenCV for ...   \n",
       "1    \\nimport cv2\\nfrom skimage import filters, mea...   \n",
       "2    Python\\n# Plan:\\n# 1. Import necessary librari...   \n",
       "3    \\n# Plan:\\n# 1. Check if the input dataframe a...   \n",
       "4    \\n# Plan:\\n# 1. Check if index column exists i...   \n",
       "..                                                 ...   \n",
       "565  1. Import the necessary libraries that will be...   \n",
       "566  \\nimport numpy as np # For working with arrays...   \n",
       "567  \\nimport cv2  # For thresholding and image pro...   \n",
       "568  \\nimport numpy as np\\nfrom skimage import io, ...   \n",
       "569  \\nimport numpy as np\\nfrom sklearn.cluster imp...   \n",
       "\n",
       "                                         full_response  \\\n",
       "0    Here is the completed code with comments on ho...   \n",
       "1    Here is the plan as comments:\\n\\n# Plan:\\n# 1....   \n",
       "2    Here is the complete code:\\n\\n```Python\\n# Pla...   \n",
       "3    Here is the complete code:\\n\\n```python\\n# Pla...   \n",
       "4    Here is the complete code:\\n\\n```python\\n# Pla...   \n",
       "..                                                 ...   \n",
       "565  1. Import the necessary libraries that will be...   \n",
       "566  1. Import the necessary Python libraries:\\n\\n`...   \n",
       "567  1. **Thresholding**: Using Otsu's thresholding...   \n",
       "568  ```python\\nimport numpy as np\\nfrom skimage im...   \n",
       "569  1. Blurring and local minimas detection:\\n    ...   \n",
       "\n",
       "                           model  \n",
       "0        llama3-8b-instruct-fp16  \n",
       "1        llama3-8b-instruct-fp16  \n",
       "2        llama3-8b-instruct-fp16  \n",
       "3        llama3-8b-instruct-fp16  \n",
       "4        llama3-8b-instruct-fp16  \n",
       "..                           ...  \n",
       "565  codellama-70b-instruct-q4_0  \n",
       "566  codellama-70b-instruct-q4_0  \n",
       "567  codellama-70b-instruct-q4_0  \n",
       "568  codellama-70b-instruct-q4_0  \n",
       "569  codellama-70b-instruct-q4_0  \n",
       "\n",
       "[11400 rows x 4 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d3e62ac8-4624-4680-821e-693f8eb9588d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ncode\\n\\ncode2\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = \"\"\"\n",
    "hallo\n",
    "```\n",
    "code\n",
    "```\n",
    "bla\n",
    "```\n",
    "code2\n",
    "```\n",
    "\"\"\"\n",
    "extract_python(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "adbd273b-e041-4532-b56a-0d6c61691ef8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "samples_llama3-8b-instruct-fp16 is different in 248 entries\n",
      "samples_llama3-70b-instruct-q4_0 is different in 64 entries\n",
      "samples_llama3-70b-instruct-q8_0 is different in 94 entries\n",
      "samples_command-r-plus-104b-q4_0 is different in 1 entries\n"
     ]
    }
   ],
   "source": [
    "# Function-mapping to extract python code from full_response\n",
    "tmp_dir = \"tmp_data/\"\n",
    "if not os.path.exists(tmp_dir):\n",
    "    os.mkdir(tmp_dir)\n",
    "\n",
    "df[\"completion\"] = df[\"full_response\"].astype(str).apply(extract_python)\n",
    "grouped = df.groupby(\"model\")\n",
    "\n",
    "for name, group in grouped:\n",
    "    records = group.drop(\"model\", axis=1).to_dict(\"records\")\n",
    "    write_jsonl(f\"{tmp_dir}/samples_{name}.jsonl\", records)\n",
    "\n",
    "# Testing code after \n",
    "for filename in os.listdir(\"data\"):\n",
    "    jsonl_file = filename.endswith(\".jsonl\") and not filename.endswith(\"results.jsonl\") and not filename.endswith(\"bia.jsonl\")\n",
    "    results_jsonl_file = filename.endswith(\"_results.jsonl\")\n",
    "    if jsonl_file:\n",
    "        model_id = filename.split(\".jsonl\")[0]\n",
    "        df_orig = pd.read_json(directory+filename, lines=True)\n",
    "        df_new = pd.read_json(f\"{tmp_dir}{model_id}.jsonl\", lines=True)\n",
    "        \n",
    "        if not df_orig.equals(df_new):\n",
    "            # checks inequalities\n",
    "            num_diff = np.size(np.where(~np.all((df_orig == df_new).to_numpy(), axis=1)))\n",
    "            print(f\"{model_id} is different in {num_diff} entries\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:heb]",
   "language": "python",
   "name": "conda-env-heb-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
