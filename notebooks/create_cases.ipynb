{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66d7773-0e61-4f6a-9005-6422684826cf",
   "metadata": {},
   "source": [
    "# Creating test cases\n",
    "This notebook takes a folder of notebooks and turns them into a jsonl file in the format human_eval expects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72835d2a-3a74-4cfe-91a6-2349a342105c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "61ff314f-fc13-4f95-987d-68803d568023",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_notebook_directory = './human-eval-bia/' # must end with /\n",
    "# Specify the filename to save the .jsonl file\n",
    "target_jsonl_filename = '../data/human-eval-bia.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66c6c23d-464d-4540-a58c-09683e70bb11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'task_id': './human-eval-bia/filtering_0.ipynb', 'prompt': 'def detect_edges(image):\\n    \"\"\"\\n    Applies an edge-detection filter to an image.\\n    \"\"\"', 'canonical_solution': '\\n    from scipy.ndimage import sobel\\n    filtered_image = sobel(image)\\n    return filtered_image', 'entry_point': 'detect_edges', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n    ])\\n\\n    result = candidate(image)\\n    left_column = result[:,0]\\n    center_columns = result[:,1:4]\\n    right_column = result[:,-1]\\n\\n    #print(\"left\", left_column)\\n    #print(\"center\", center_columns)\\n    #print(\"right\", right_column)\\n\\n    assert left_column.max() == 0 and left_column.min() == 0\\n    assert center_columns.max() != 0 or center_columns.min() != 0\\n    assert right_column.max() == 0 and left_column.min() == 0\\n'}\n",
      "{'task_id': './human-eval-bia/filtering_1.ipynb', 'prompt': 'def remove_noise_edge_preserving(image, radius:int=1):\\n    \"\"\"\\n    Applies an edge-preserving noise-removal filter to an image.\\n    \"\"\"', 'canonical_solution': '\\n    from scipy.ndimage import median_filter\\n    filtered_image = median_filter(image, size=radius * 2 + 1)\\n    return filtered_image', 'entry_point': 'remove_noise_edge_preserving', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [1,1,2,2,2],\\n        [1,2,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,1,2,2],\\n        [1,1,2,2,2],\\n    ])\\n\\n    reference = np.asarray([\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n        [1,1,2,2,2],\\n    ])\\n    \\n    assert np.array_equal(candidate(image), reference)\\n\\n    assert candidate(image, radius=5).mean() == 2\\n\\n'}\n",
      "{'task_id': './human-eval-bia/hello_world.ipynb', 'prompt': 'def return_hello_world():\\n    \"\"\"\\n    Returns the string \"hello world\".\\n    \"\"\"', 'canonical_solution': '\\n    return \"hello world\"', 'entry_point': 'return_hello_world', 'test': 'def check(candidate):\\n    assert candidate() == \"hello world\"'}\n",
      "{'task_id': './human-eval-bia/label_processing_0.ipynb', 'prompt': 'def remove_labels_on_edges(label_image):\\n    \"\"\"\\n    Takes a label_image and removes all objects which touch the image border.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    return skimage.segmentation.clear_border(label_image)', 'entry_point': 'remove_labels_on_edges', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [1,2,2,0,0],\\n        [1,2,2,0,0],\\n        [1,0,0,3,0],\\n        [0,0,0,4,0],\\n    ]))\\n\\n    # -1 becaue background counts\\n    assert len(np.unique(result)) - 1 == 2\\n    assert result.shape[0] == 5\\n    assert result.shape[1] == 5'}\n",
      "{'task_id': './human-eval-bia/label_processing_1.ipynb', 'prompt': 'def label_sequentially(label_image):\\n    \"\"\"\\n    Takes a label_image with n labels and relabels the objects, \\n    to make sure all integer labels between 0 and n are used. \\n    No gaps are there.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    return skimage.segmentation.relabel_sequential(label_image)[0]', 'entry_point': 'label_sequentially', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n        [0,4,0,0,0],\\n        [0,0,5,0,0],\\n        [0,0,0,6,0],\\n    ])) \\n\\n    # -1 becaue background counts\\n    assert len(np.unique(result)) - 1 == 4\\n    assert result.max() == 4\\n    assert result.shape[0] == 5\\n    assert result.shape[1] == 5'}\n",
      "{'task_id': './human-eval-bia/label_processing_2.ipynb', 'prompt': 'def remove_small_labels(label_image, size_threshold:int=0):\\n    \"\"\"\\n    Takes a label_image and removes all objects that are smaller than a given size_threshold.\\n    \"\"\"', 'canonical_solution': '\\n    import pyclesperanto_prototype as cle\\n    return cle.exclude_small_labels(label_image, maximum_size=size_threshold)', 'entry_point': 'remove_small_labels', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [1,2,2,0,0],\\n        [1,2,2,0,0],\\n        [1,0,0,3,0],\\n        [0,0,0,4,0],\\n    ]), size_threshold=2)\\n\\n    reference = np.asarray([\\n        [0,0,0,0,0],\\n        [1,2,2,0,0],\\n        [1,2,2,0,0],\\n        [1,0,0,0,0],\\n        [0,0,0,0,0],\\n    ])\\n\\n    assert np.array_equal(reference, result)'}\n",
      "{'task_id': './human-eval-bia/label_processing_3.ipynb', 'prompt': 'def expand_labels_without_overlap(label_image, radius:int=1):\\n    \"\"\"\\n    Takes a label_image and enlarges all labels by a given radius, without\\n    labels overwriting each other.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    return skimage.segmentation.expand_labels(label_image, distance=radius)', 'entry_point': 'expand_labels_without_overlap', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,1,1,3,0],\\n        [0,1,1,3,0],\\n        [0,0,0,0,0],\\n        [2,0,0,0,0],\\n    ]))\\n\\n    reference = np.asarray([\\n        [0,1,1,3,0],\\n        [1,1,1,3,3],\\n        [1,1,1,3,3],\\n        [2,1,1,3,0],\\n        [2,2,0,0,0],\\n    ])\\n\\n    assert np.array_equal(reference, result)'}\n",
      "{'task_id': './human-eval-bia/label_processing_4.ipynb', 'prompt': 'def binary_closing(binary_image, radius:int=1):\\n    \"\"\"\\n    Applies binary closing to a binary_image with a square footprint with a given radius.\\n    \"\"\"', 'canonical_solution': '\\n    import numpy as np\\n    import skimage\\n    size = radius * 2 + 1\\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))', 'entry_point': 'binary_closing', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,0,0,0,0,0],\\n        [0,0,0,0,0,0,0],\\n        [0,0,1,0,1,0,0],\\n        [0,0,1,0,1,0,0],\\n        [0,0,1,0,1,0,0],\\n        [0,0,0,0,0,0,0],\\n        [0,0,0,0,0,0,0],\\n    ]))\\n\\n    reference = np.asarray([\\n        [0,0,0,0,0,0,0],\\n        [0,0,0,0,0,0,0],\\n        [0,0,1,1,1,0,0],\\n        [0,0,1,1,1,0,0],\\n        [0,0,1,1,1,0,0],\\n        [0,0,0,0,0,0,0],\\n        [0,0,0,0,0,0,0],\\n    ])\\n\\n    assert np.array_equal(reference, result)'}\n",
      "{'task_id': './human-eval-bia/measure_0.ipynb', 'prompt': 'def measure_intensity_of_labels(label_image, intensity_image):\\n    \"\"\"\\n    Takes a label image and an intensity image, and returns a list of mean intensities \\n    of all pixels in the intensity image, belonging to a given label.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    stats = skimage.measure.regionprops(label_image, intensity_image)\\n    return [s.mean_intensity for s in stats]', 'entry_point': 'measure_intensity_of_labels', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    label_image = np.asarray([\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n        [0,2,2,2,2],\\n        [0,3,3,0,0],\\n        [0,0,0,4,0],\\n    ])\\n\\n    intensity_image = np.asarray([\\n        [0,2,0,0,0],\\n        [0,0,0,0,0],\\n        [0,3,3,4,4],\\n        [0,3,3,0,0],\\n        [0,0,0,5,0],\\n    ])\\n    \\n    result = candidate(label_image, intensity_image) \\n    assert np.array_equal([2,3.5,3,5], result)'}\n",
      "{'task_id': './human-eval-bia/measure_1.ipynb', 'prompt': 'def measure_pixel_count_of_labels(label_image):\\n    \"\"\"\\n    Takes a label image and returns a list of counts of number of pixels per label.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    stats = skimage.measure.regionprops(label_image)\\n    return [s.area for s in stats]', 'entry_point': 'measure_pixel_count_of_labels', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n        [0,2,2,2,0],\\n        [0,3,3,0,0],\\n        [0,0,0,4,0],\\n    ])) \\n    assert np.array_equal([1,3,2,1], result)'}\n",
      "{'task_id': './human-eval-bia/measure_2.ipynb', 'prompt': 'def measure_mean_image_intensity(image):\\n    \"\"\"\\n    Takes an image and returns its mean intensity\\n    \"\"\"', 'canonical_solution': '\\n    import numpy as np\\n    return np.asarray(image).mean()', 'entry_point': 'measure_mean_image_intensity', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [1,2,3,4,5],\\n        [1,2,3,4,5],\\n        [1,2,3,4,5],\\n        [1,2,3,4,5],\\n        [1,2,3,4,5],\\n    ])) \\n    assert result == 3'}\n",
      "{'task_id': './human-eval-bia/measure_3.ipynb', 'prompt': 'def measure_properties_of_regions(label_image, intensity_image):\\n    \"\"\"\\n    Takes a label image and an intensity image, and returns pandas dataframe\\n    with measurements for area, perimeter and mean_intensity.\\n    \"\"\"', 'canonical_solution': \"\\n    import skimage\\n    import pandas as pd\\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\\n    return pd.DataFrame(stats)\", 'entry_point': 'measure_properties_of_regions', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    label_image = np.asarray([\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n        [0,2,2,2,2],\\n        [0,3,3,0,0],\\n        [0,0,0,4,0],\\n    ])\\n\\n    intensity_image = np.asarray([\\n        [0,2,0,0,0],\\n        [0,0,0,0,0],\\n        [0,3,3,4,4],\\n        [0,3,3,0,0],\\n        [0,0,0,5,0],\\n    ])\\n    \\n    result = candidate(label_image, intensity_image) \\n    \\n    assert \"mean_intensity\" in result.columns\\n    assert \"area\" in result.columns\\n    assert \"perimeter\" in result.columns\\n    assert len(result.columns) == 3\\n    assert len(result) == 4'}\n",
      "{'task_id': './human-eval-bia/measure_4.ipynb', 'prompt': 'def count_overlapping_regions(label_image_1, label_image_2):\\n    \"\"\"\\n    Takes two label images and counts how many objects in label_image_1 overlap \\n    with any label in label_image_2 with at least one pixel.\\n    It returns the count of overlapping objects.\\n    \"\"\"', 'canonical_solution': \"\\n    import skimage\\n    import pandas as pd\\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()\", 'entry_point': 'count_overlapping_regions', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    label_image_1 = np.asarray([\\n        [0,1,0,0,0],\\n        [0,0,2,0,0],\\n        [0,0,0,3,0],\\n        [0,4,4,0,0],\\n        [0,0,0,5,0],\\n    ])\\n\\n    label_image_2 = np.asarray([\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,1,0],\\n        [0,0,1,0,0],\\n        [0,0,0,1,0],\\n    ])\\n    \\n    result = candidate(label_image_1, label_image_2) \\n    assert result == 3\\n\\n    result = candidate(label_image_2, label_image_1)\\n    assert result == 1\\n'}\n",
      "{'task_id': './human-eval-bia/measure_5.ipynb', 'prompt': 'def count_number_of_touching_neighbors(label_image):\\n    \"\"\"\\n    Takes a label image and returns a list of number of touching neighbors \\n    for each labeled object.\\n    \"\"\"', 'canonical_solution': '\\n    import numpy as np\\n    import pyclesperanto_prototype as cle\\n\\n    touch_matrix = cle.generate_touch_matrix(label_image)\\n    cle.set_row(touch_matrix, 0, 0)\\n    cle.set_column(touch_matrix, 0, 0)\\n\\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:]', 'entry_point': 'count_number_of_touching_neighbors', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    label_image = np.asarray([\\n        [0,0,0,0,0],\\n        [0,0,2,2,0],\\n        [0,0,1,3,0],\\n        [0,4,1,0,0],\\n        [0,0,0,0,0],\\n    ])\\n    print(candidate(label_image))\\n    assert np.array_equal(candidate(label_image), [3, 2, 2, 1])'}\n",
      "{'task_id': './human-eval-bia/project_0.ipynb', 'prompt': 'def maximum_intensity_projection(image):\\n    \"\"\"\\n    Performs a maximum intensity projection along the first axis of an image.\\n    \"\"\"', 'canonical_solution': '\\n    import numpy as np\\n    return np.asarray(image).max(axis=0)', 'entry_point': 'maximum_intensity_projection', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [0,0,0,0,0,0],\\n        [0,1,0,0,2,0],\\n        [0,0,0,0,0,0],\\n        [0,0,0,0,0,0],\\n        [0,4,0,0,3,0],\\n        [0,0,0,0,0,0],\\n    ])\\n\\n    reference = np.asarray(\\n        [0,4,0,0,3,0]\\n    )\\n    \\n    assert np.array_equal(candidate(image), reference)\\n'}\n",
      "{'task_id': './human-eval-bia/project_1.ipynb', 'prompt': 'def sum_intensity_projection(image):\\n    \"\"\"\\n    Performs a maximum intensity projection along the first axis of an image.\\n    \"\"\"', 'canonical_solution': '\\n    import numpy as np\\n    return np.asarray(image).sum(axis=0)', 'entry_point': 'sum_intensity_projection', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [0,0,0,0,0,0],\\n        [0,1,0,0,3,0],\\n        [0,0,0,0,0,0],\\n        [0,0,0,0,0,0],\\n        [0,4,0,0,6,0],\\n        [0,0,0,0,0,0],\\n    ])\\n\\n    reference = np.asarray(\\n        [0,5,0,0,9,0]\\n    )\\n    \\n    assert np.array_equal(candidate(image), reference)\\n'}\n",
      "{'task_id': './human-eval-bia/segmentation_0.ipynb', 'prompt': 'def label_binary_image_and_count_labels(binary_image):\\n    \"\"\"\\n    Consumes as input a binary image, applies connected component labeling to it, \\n    counts the labeled objects and returns their count as single number.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    import numpy as np\\n    label_image = skimage.measure.label(binary_image)\\n\\n    return len(np.unique(label_image)) - 1', 'entry_point': 'label_binary_image_and_count_labels', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n        [1,0,0,0,0],\\n        [0,0,0,1,0],\\n    ])) == 3\\n\\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n    ])) == 1\\n\\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n    ])) == 0'}\n",
      "{'task_id': './human-eval-bia/segmentation_1.ipynb', 'prompt': 'def apply_otsu_threshold_and_count_postiive_pixels(image):\\n    \"\"\"\\n    Takes an image, applies Otsu\\'s threshold method to it to create a binary image and \\n    counts the positive pixels.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    import numpy as np\\n    binary_image = image > skimage.filters.threshold_otsu(image)\\n\\n    result = np.sum(binary_image)\\n\\n    return result', 'entry_point': 'apply_otsu_threshold_and_count_postiive_pixels', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [1,1,1,0,0],\\n        [1,1,1,0,0],\\n        [1,0,0,0,0],\\n        [0,0,0,1,0],\\n    ])) == 8\\n\\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,1,0,0,0],\\n        [1,2,1,0,0],\\n        [0,1,3,4,0],\\n        [0,1,4,1,0],\\n    ])) == 4\\n\\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n        [0,0,0,0,0],\\n    ])) == 0'}\n",
      "{'task_id': './human-eval-bia/segmentation_2.ipynb', 'prompt': 'def region_growing_segmentation(image, point):\\n    \"\"\"\\n    Segments an image using the region-growing/flood filling \\n    starting from a single point.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    return skimage.segmentation.flood(image, point)', 'entry_point': 'region_growing_segmentation', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [1,1,1,1,1,1,1,1,1,1],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [1,1,1,1,1,1,1,1,1,1],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n    ]), (5,5)) \\n\\n    assert result.sum() * 1 == 16\\n    assert result.min() == 0\\n    assert result.max() == 1'}\n",
      "{'task_id': './human-eval-bia/transform_0.ipynb', 'prompt': 'def crop_quarter_image(image):\\n    \"\"\"\\n    Crops out the first half image in both dimensions (width and height). \\n    The resulting image will be of quarter size compared to the original image.\\n    \"\"\"', 'canonical_solution': '\\n    width = image.shape[1]\\n    height = image.shape[0]\\n\\n    return image[:int(width/2),:int(height/2)]', 'entry_point': 'crop_quarter_image', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [0,0,0,0,0,0],\\n        [0,1,0,0,2,0],\\n        [0,0,0,0,0,0],\\n        [0,0,0,0,0,0],\\n        [0,4,0,0,3,0],\\n        [0,0,0,0,0,0],\\n    ])\\n\\n    reference = np.asarray([\\n        [0,0,0],\\n        [0,1,0],\\n        [0,0,0],\\n    ])\\n    \\n    assert np.array_equal(candidate(image), reference)\\n'}\n",
      "{'task_id': './human-eval-bia/transform_1.ipynb', 'prompt': 'def crop_quarter_image(image):\\n    \"\"\"\\n    Crops out the first half image in both dimensions (width and height). \\n    The resulting image will be of quarter size compared to the original image.\\n    \"\"\"', 'canonical_solution': '\\n    width = image.shape[1]\\n    height = image.shape[0]\\n\\n    return image[:int(width/2),:int(height/2)]', 'entry_point': 'crop_quarter_image', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [0,0,0,0,0,0],\\n        [0,1,0,0,2,0],\\n        [0,0,0,0,0,0],\\n        [0,0,0,0,0,0],\\n        [0,4,0,0,3,0],\\n        [0,0,0,0,0,0],\\n    ])\\n\\n    reference = np.asarray([\\n        [0,0,0],\\n        [0,1,0],\\n        [0,0,0],\\n    ])\\n    \\n    assert np.array_equal(candidate(image), reference)\\n'}\n",
      "{'task_id': './human-eval-bia/transform_2.ipynb', 'prompt': 'def rotate_image_by_90_degrees(image):\\n    \"\"\"\\n    Rotates an image by 90 degrees clockwise around the center of the image.\\n    \"\"\"', 'canonical_solution': '\\n    import pyclesperanto_prototype as cle\\n    return cle.rotate(image, angle_around_z_in_degrees=90)', 'entry_point': 'rotate_image_by_90_degrees', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [0,0,0,0,0,0],\\n        [0,1,0,0,2,0],\\n        [0,0,0,0,0,0],\\n        [0,0,0,0,0,0],\\n        [0,4,0,0,3,0],\\n        [0,0,0,0,0,0],\\n    ])\\n\\n    reference = np.asarray([\\n        [0,0,0,0,0,0],\\n        [0,4,0,0,1,0],\\n        [0,0,0,0,0,0],\\n        [0,0,0,0,0,0],\\n        [0,3,0,0,2,0],\\n        [0,0,0,0,0,0],\\n    ])\\n    \\n    assert np.array_equal(candidate(image), reference)\\n'}\n",
      "{'task_id': './human-eval-bia/transform_3.ipynb', 'prompt': 'def subsample_image(image, n:int=2):\\n    \"\"\"\\n    Subsamples an image by taking the skipping every n\\'th pixel in X and Y.\\n    \"\"\"', 'canonical_solution': '\\n    return image[::n,::n]', 'entry_point': 'subsample_image', 'test': 'def check(candidate):\\n    import numpy as np\\n\\n    image = np.asarray([\\n        [1,2,3,4,5,6],\\n        [7,8,9,0,1,2],\\n        [3,4,5,6,7,8],\\n        [9,0,1,2,3,4],\\n        [5,6,7,8,9,0],\\n        [1,2,3,4,5,6],\\n    ])\\n\\n    reference = np.asarray([\\n        [1,3,5],\\n        [3,5,7],\\n        [5,7,9],\\n    ])\\n    \\n    assert np.array_equal(candidate(image, n=2), reference)\\n\\n    reference = np.asarray([\\n        [1,4],\\n        [9,2],\\n    ])\\n\\n    assert np.array_equal(candidate(image, n=3), reference)'}\n",
      "{'task_id': './human-eval-bia/workflow_0.ipynb', 'prompt': 'def worflow_segmentation_measurement_summary(image):\\n    \"\"\"\\n    This function implements a workflow consisting of these steps:\\n    * threshold intensity input image using Otsu\\'s method\\n    * label connected components\\n    * measure area of the labeled objects\\n    * determine mean area of all objects\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    import numpy as np\\n    binary_image = image > skimage.filters.threshold_otsu(image)\\n    label_image = skimage.measure.label(binary_image)\\n    stats = skimage.measure.regionprops(label_image)\\n    areas = [s.area for s in stats]\\n    return np.mean(areas)', 'entry_point': 'worflow_segmentation_measurement_summary', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [1,1,1,0,0],\\n        [1,1,1,0,0],\\n        [1,1,0,0,0],\\n        [0,0,0,0,0],\\n    ])) == 8\\n\\n    assert candidate(np.asarray([\\n        [1,1,0,1,1],\\n        [1,1,0,0,0],\\n        [0,0,0,1,1],\\n        [1,1,0,1,1],\\n        [0,0,0,0,0],\\n    ])) == 3\\n\\n    assert candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,1,0,1,0],\\n        [0,0,0,0,0],\\n        [0,0,1,0,0],\\n        [0,0,0,0,0],\\n    ])) == 1'}\n",
      "{'task_id': './human-eval-bia/workflow_1.ipynb', 'prompt': 'def worflow_watershed_segmentation_correction_measurement(image):\\n    \"\"\"\\n    This function implements a workflow consisting of these steps:\\n    * blurs the image a bit\\n    * detect local minima in the blurred image\\n    * apply watershed segmentation flooding the blurred image from the \\n      detected minima to retrieve a label image\\n    * remove all objects which touch the image border\\n    * measure the area of all remaining objects together\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    blurred = skimage.filters.gaussian(image, sigma=1)\\n    minima = skimage.morphology.local_minima(blurred)\\n    spots = skimage.measure.label(minima)\\n    labels = skimage.segmentation.watershed(blurred, spots)\\n    labels_without_border = skimage.segmentation.clear_border(labels)   \\n    binary = labels_without_border > 0\\n    return binary.sum()', 'entry_point': 'worflow_watershed_segmentation_correction_measurement', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [1,1,1,1,1,1,1,1,1,1],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [1,1,1,1,1,1,1,1,1,1],\\n        [0,0,1,0,0,0,0,1,0,0],\\n        [0,0,1,0,0,0,0,1,0,0],\\n    ])) \\n\\n    # if only the 4x4 pixels are segmented:\\n    assert result >= 16\\n    # if it also considers borders as part of the center object:\\n    assert result <= 36 \\n'}\n",
      "{'task_id': './human-eval-bia/workflow_2.ipynb', 'prompt': 'def worflow_segmentation_counting(image):\\n    \"\"\"\\n    This function segments objects in an image with intensity above average \\n    and returns their count.\\n    \"\"\"', 'canonical_solution': '\\n    import skimage\\n    import numpy as np\\n    average_intensity = np.asarray(image).mean()\\n    binary = image > average_intensity\\n    labels = skimage.measure.label(binary)\\n    return labels.max()', 'entry_point': 'worflow_segmentation_counting', 'test': 'def check(candidate):\\n    import numpy as np\\n    \\n    result = candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,1,0,0,0],\\n        [0,0,0,2,0],\\n        [0,1,0,0,0],\\n        [0,0,0,0,0],\\n    ])) \\n    assert result == 3\\n\\n    result = candidate(np.asarray([\\n        [0,0,0,0,0],\\n        [0,100,0,90,0],\\n        [0,0,0,0,0],\\n        [0,110,0,80,0],\\n        [0,0,0,0,0],\\n    ])) \\n    assert result == 4'}\n"
     ]
    }
   ],
   "source": [
    "list_of_cases = []\n",
    "\n",
    "\n",
    "# List all files in the current directory\n",
    "files = os.listdir(source_notebook_directory)\n",
    "\n",
    "# Iterate through the files and print names ending with .ipynb\n",
    "for file in files:\n",
    "    if file.endswith('.ipynb'):\n",
    "        notebook_filename = source_notebook_directory + file\n",
    "        \n",
    "        # Load and parse the notebook\n",
    "        with open(notebook_filename, 'r') as file:\n",
    "            notebook = json.load(file)\n",
    "        \n",
    "        task_id = notebook_filename\n",
    "        prompt = None\n",
    "        canonical_solution = None\n",
    "        entry_point = None\n",
    "        test = None\n",
    "        \n",
    "        # Iterate through the cells and print the source of code cells\n",
    "        for cell in notebook['cells']:\n",
    "            if cell['cell_type'] == 'code':\n",
    "                # Joining the lines of code for better readability\n",
    "                code = ''.join(cell['source'])\n",
    "                # print('\\n\\nCODE\\n\\n',code)\n",
    "        \n",
    "                if code.startswith('check('):\n",
    "                    entry_point = code.strip().replace(\"check(\",\"\").replace(\")\",\"\").strip()\n",
    "                elif '\"\"\"' in code:\n",
    "                    temp = code.split('\"\"\"')\n",
    "                    canonical_solution = temp[-1]\n",
    "                    temp[-1] = \"\"\n",
    "                    prompt = '\"\"\"'.join(temp)\n",
    "                elif 'def check(' in code:\n",
    "                    test = code \n",
    "                elif len(code.strip()) == 0:\n",
    "                    pass\n",
    "                else:\n",
    "                    sample = code[:20]\n",
    "                    warnings.warn(f\"I had issues reading a cell in {task_id} starting with \")\n",
    "                    \n",
    "        if prompt is None:\n",
    "            warnings.warn(f\"Couldn't extract prompt from {task_id}.\")\n",
    "        elif canonical_solution is None:\n",
    "            warnings.warn(f\"Couldn't extract canonical_solution from {task_id}.\")\n",
    "        elif entry_point is None:\n",
    "            warnings.warn(f\"Couldn't extract entry_point from {task_id}.\")\n",
    "        \n",
    "        test_case = {\n",
    "            'task_id':task_id,\n",
    "            'prompt':prompt,\n",
    "            'canonical_solution':canonical_solution,\n",
    "            'entry_point':entry_point,\n",
    "            'test':test\n",
    "        }\n",
    "\n",
    "        print(test_case)\n",
    "        list_of_cases.append(test_case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "339ee8e9-457e-4d4f-a521-f758c36fb3cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data successfully saved to ../data/human-eval-bia.jsonl.\n"
     ]
    }
   ],
   "source": [
    "# Open the file in write mode and save the dictionaries\n",
    "with open(target_jsonl_filename, 'w') as file:\n",
    "    for dictionary in list_of_cases:\n",
    "        # Convert dictionary to a JSON formatted string and write it\n",
    "        json_str = json.dumps(dictionary)\n",
    "        file.write(json_str + '\\n')\n",
    "\n",
    "print(f'Data successfully saved to {target_jsonl_filename}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8315490-aa34-44c5-b1e8-048270e4f14a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de62da25-c79d-437a-b586-7e139abfe1ac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
