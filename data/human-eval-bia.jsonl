{"task_id": "./human-eval-bia/filtering_0.ipynb", "prompt": "def detect_edges(image):\n    \"\"\"\n    Applies an edge-detection filter to an image.\n    \"\"\"", "canonical_solution": "\n    from scipy.ndimage import sobel\n    filtered_image = sobel(image)\n    return filtered_image", "entry_point": "detect_edges", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n    ])\n\n    result = candidate(image)\n    left_column = result[:,0]\n    center_columns = result[:,1:4]\n    right_column = result[:,-1]\n\n    assert left_column.max() == 0 and left_column.min() == 0\n    assert center_columns.max() != 0 or center_columns.min() != 0\n    assert right_column.max() == 0 and left_column.min() == 0"}
{"task_id": "./human-eval-bia/filtering_1.ipynb", "prompt": "def remove_noise_edge_preserving(image, radius:int=1):\n    \"\"\"\n    Applies an edge-preserving noise-removal filter to an image.\n    \"\"\"", "canonical_solution": "\n    from scipy.ndimage import median_filter\n    filtered_image = median_filter(image, size=radius * 2 + 1)\n    return filtered_image", "entry_point": "remove_noise_edge_preserving", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,2,2,2],\n        [1,2,2,2,2],\n        [1,1,2,2,2],\n        [1,1,1,2,2],\n        [1,1,2,2,2],\n    ])\n\n    reference = np.asarray([\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n        [1,1,2,2,2],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n\n    assert candidate(image, radius=5).mean() == 2\n\n"}
{"task_id": "./human-eval-bia/filtering_2.ipynb", "prompt": "def sum_images(image1, image2):\n    \"\"\"\n    Sums two images pixel-by-pixel and returns the result\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image1) + np.asarray(image2)", "entry_point": "sum_images", "test": "def check(candidate):\n    import numpy as np\n\n    image1 = np.random.random((5,6))\n    image2 = np.random.random((5,6))\n    sum_image = image1 + image2\n    \n    assert np.allclose(candidate(image1, image2), sum_image)\n\n    image1 =    [[1,2,3], [4,5,6]]\n    image2 =    [[5,6,7], [0,1,2]]\n    sum_image = [[6,8,10],[4,6,8]]\n    \n    assert np.allclose(candidate(image1, image2), sum_image)\n"}
{"task_id": "./human-eval-bia/filtering_3.ipynb", "prompt": "def convolve_images(image, kernel_image):\n    \"\"\"\n    Convolve an image with a kernel_image and return the result\n    \"\"\"", "canonical_solution": "\n    import scipy\n    return scipy.ndimage.convolve(image, kernel_image)\n    ", "entry_point": "convolve_images", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n    kernel= np.asarray([\n        [0,1,0],\n        [1,1,1],\n        [0,2,0],\n    ])\n\n    reference = np.asarray([\n        [0,1,0,0,0,0,0],\n        [1,1,1,0,0,0,0],\n        [0,2,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,1,1,1,0],\n        [0,0,0,0,2,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n\n    \n    image = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,1,1,0,0,0,0],\n        [1,2,2,1,0,0,0],\n        [0,2,2,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n   \n"}
{"task_id": "./human-eval-bia/filtering_4.ipynb", "prompt": "def subtract_background_tophat(image, radius:int=1):\n    \"\"\"\n    Applies a top-hat filter with a given radius to an image with dark background (low values) and bright foreground (high values).\n    \"\"\"", "canonical_solution": "\n    from skimage.morphology import white_tophat\n    from skimage.morphology import disk\n    filtered_image = white_tophat(image, footprint=disk(radius))\n    \n    return filtered_image", "entry_point": "subtract_background_tophat", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,1,1,1,1,1,1,1],\n        [1,2,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,1,1,1,1,1,1],\n        [1,1,4,1,1,1,1,1],\n        [1,1,1,1,1,1,2,1],\n        [1,1,1,1,1,1,1,1],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0,0],\n        [0,0,3,0,0,0,0,0],\n        [0,0,0,0,0,0,1,0],\n        [0,0,0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n    assert np.array_equal(candidate(reference), reference)\n\n    # note this test case is kept simple to allow also other top-hat implementations (e.g. with a square footpint) to pass\n"}
{"task_id": "./human-eval-bia/filtering_5.ipynb", "prompt": "def deconvolve_image(image, kernel_image):\n    \"\"\"\n    Deconvolve an image with a kernel_image and return the result.\n    \"\"\"", "canonical_solution": "\n    from scipy import fftpack\n\n    # adapted from: https://stackoverflow.com/questions/17473917/is-there-a-equivalent-of-scipy-signal-deconvolve-for-2d-arrays\n    star_fft = fftpack.fftshift(fftpack.fftn(image))\n    psf_fft = fftpack.fftshift(fftpack.fftn(kernel_image))\n    return fftpack.fftshift(fftpack.ifftn(fftpack.ifftshift(star_fft/psf_fft)))\n    ", "entry_point": "deconvolve_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,1,0,0,0,0,0],\n        [1,1,1,0,0,0,0],\n        [0,2,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,1,1,1,0],\n        [0,0,0,0,2,0,0],\n    ])\n    kernel= np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,1,0,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,0,2,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,1,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    \n    assert np.allclose(reference, result)\n\n    \n    image = np.asarray([\n        [0,1,1,0,0,0,0],\n        [1,2,2,1,0,0,0],\n        [0,2,2,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,1,1,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    result = candidate(image, kernel)\n    assert np.allclose(reference, result)\n   \n"}
{"task_id": "./human-eval-bia/hello_world.ipynb", "prompt": "def return_hello_world():\n    \"\"\"\n    Returns the string \"hello world\".\n    \"\"\"", "canonical_solution": "\n    return \"hello world\"", "entry_point": "return_hello_world", "test": "def check(candidate):\n    assert candidate() == \"hello world\""}
{"task_id": "./human-eval-bia/label_processing_0.ipynb", "prompt": "def remove_labels_on_edges(label_image):\n    \"\"\"\n    Takes a label_image and removes all objects which touch the image border.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.clear_border(label_image)", "entry_point": "remove_labels_on_edges", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,3,0],\n        [0,0,0,4,0],\n    ]))\n\n    # -1 becaue background counts\n    assert len(np.unique(result)) - 1 == 2\n    assert result.shape[0] == 5\n    assert result.shape[1] == 5"}
{"task_id": "./human-eval-bia/label_processing_1.ipynb", "prompt": "def label_sequentially(label_image):\n    \"\"\"\n    Takes a label_image with n labels and relabels the objects, \n    to make sure all integer labels between 0 and n are used. \n    No gaps are there.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.relabel_sequential(label_image)[0]", "entry_point": "label_sequentially", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,4,0,0,0],\n        [0,0,5,0,0],\n        [0,0,0,6,0],\n    ])) \n\n    # -1 becaue background counts\n    assert len(np.unique(result)) - 1 == 4\n    assert result.max() == 4\n    assert result.shape[0] == 5\n    assert result.shape[1] == 5"}
{"task_id": "./human-eval-bia/label_processing_2.ipynb", "prompt": "def remove_small_labels(label_image, size_threshold:int=0):\n    \"\"\"\n    Takes a label_image and removes all objects that are smaller than a given size_threshold.\n    \"\"\"", "canonical_solution": "\n    import pyclesperanto_prototype as cle\n    return cle.exclude_small_labels(label_image, maximum_size=size_threshold)", "entry_point": "remove_small_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,3,0],\n        [0,0,0,4,0],\n    ]), size_threshold=2)\n\n    reference = np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,0,0],\n        [0,0,0,0,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "./human-eval-bia/label_processing_3.ipynb", "prompt": "def expand_labels_without_overlap(label_image, radius:int=1):\n    \"\"\"\n    Takes a label_image and enlarges all labels by a given radius, without\n    labels overwriting each other.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.expand_labels(label_image, distance=radius)", "entry_point": "expand_labels_without_overlap", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,1,3,0],\n        [0,1,1,3,0],\n        [0,0,0,0,0],\n        [2,0,0,0,0],\n    ]))\n\n    reference = np.asarray([\n        [0,1,1,3,0],\n        [1,1,1,3,3],\n        [1,1,1,3,3],\n        [2,1,1,3,0],\n        [2,2,0,0,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "./human-eval-bia/label_processing_4.ipynb", "prompt": "def binary_closing(binary_image, radius:int=1):\n    \"\"\"\n    Applies binary closing to a binary_image with a square footprint with a given radius.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import skimage\n    size = radius * 2 + 1\n    return skimage.morphology.binary_closing(binary_image, footprint=np.ones((size, size)))", "entry_point": "binary_closing", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,1,0,1,0,0],\n        [0,0,1,0,1,0,0],\n        [0,0,1,0,1,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ]))\n\n    reference = np.asarray([\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,1,1,1,0,0],\n        [0,0,0,0,0,0,0],\n        [0,0,0,0,0,0,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "./human-eval-bia/label_processing_5.ipynb", "prompt": "def map_pixel_count_of_labels(label_image):\n    \"\"\"\n    Takes a label_image, determines the pixel-count per label and creates an image where the label values are replaced by the corresponding pixel count.\n    \"\"\"", "canonical_solution": "\n    import pyclesperanto_prototype as cle\n    return cle.pixel_count_map(label_image)", "entry_point": "map_pixel_count_of_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,2,2,0,0],\n        [1,2,2,0,0],\n        [1,0,0,3,0],\n        [0,0,0,4,0],\n    ]))\n\n    reference = np.asarray([\n        [0,0,0,0,0],\n        [3,4,4,0,0],\n        [3,4,4,0,0],\n        [3,0,0,1,0],\n        [0,0,0,1,0],\n    ])\n\n    assert np.array_equal(reference, result)"}
{"task_id": "./human-eval-bia/measure_0.ipynb", "prompt": "def measure_intensity_of_labels(label_image, intensity_image):\n    \"\"\"\n    Takes a label image and an intensity image, and returns a list of mean intensities \n    of all pixels in the intensity image, belonging to a given label.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image, intensity_image)\n    return [s.mean_intensity for s in stats]", "entry_point": "measure_intensity_of_labels", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,2],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])\n\n    intensity_image = np.asarray([\n        [0,2,0,0,0],\n        [0,0,0,0,0],\n        [0,3,3,4,4],\n        [0,3,3,0,0],\n        [0,0,0,5,0],\n    ])\n    \n    result = candidate(label_image, intensity_image) \n    assert np.array_equal([2,3.5,3,5], result)"}
{"task_id": "./human-eval-bia/measure_1.ipynb", "prompt": "def measure_pixel_count_of_labels(label_image):\n    \"\"\"\n    Takes a label image and returns a list of counts of number of pixels per label.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    stats = skimage.measure.regionprops(label_image)\n    return [s.area for s in stats]", "entry_point": "measure_pixel_count_of_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,0],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])) \n    assert np.array_equal([1,3,2,1], result)"}
{"task_id": "./human-eval-bia/measure_2.ipynb", "prompt": "def measure_mean_image_intensity(image):\n    \"\"\"\n    Takes an image and returns its mean intensity\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).mean()", "entry_point": "measure_mean_image_intensity", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n        [1,2,3,4,5],\n    ])) \n    assert result == 3"}
{"task_id": "./human-eval-bia/measure_3.ipynb", "prompt": "def measure_properties_of_regions(label_image, intensity_image):\n    \"\"\"\n    Takes a label image and an intensity image, and returns pandas dataframe\n    with measurements for area, perimeter and mean_intensity.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image, intensity_image, properties=('area', 'perimeter', 'mean_intensity'))\n    return pd.DataFrame(stats)", "entry_point": "measure_properties_of_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,2,2,2,2],\n        [0,3,3,0,0],\n        [0,0,0,4,0],\n    ])\n\n    intensity_image = np.asarray([\n        [0,2,0,0,0],\n        [0,0,0,0,0],\n        [0,3,3,4,4],\n        [0,3,3,0,0],\n        [0,0,0,5,0],\n    ])\n    \n    result = candidate(label_image, intensity_image) \n    \n    assert \"mean_intensity\" in result.columns\n    assert \"area\" in result.columns\n    assert \"perimeter\" in result.columns\n    assert len(result.columns) == 3\n    assert len(result) == 4"}
{"task_id": "./human-eval-bia/measure_4.ipynb", "prompt": "def count_overlapping_regions(label_image_1, label_image_2):\n    \"\"\"\n    Takes two label images and counts how many objects in label_image_1 overlap \n    with any label in label_image_2 with at least one pixel.\n    It returns the count of overlapping objects.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = skimage.measure.regionprops_table(label_image_1, label_image_2, properties=('mean_intensity',))\n    return (pd.DataFrame(stats)['mean_intensity'] > 0).sum()", "entry_point": "count_overlapping_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image_1 = np.asarray([\n        [0,1,0,0,0],\n        [0,0,2,0,0],\n        [0,0,0,3,0],\n        [0,4,4,0,0],\n        [0,0,0,5,0],\n    ])\n\n    label_image_2 = np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,1,0],\n        [0,0,1,0,0],\n        [0,0,0,1,0],\n    ])\n    \n    result = candidate(label_image_1, label_image_2) \n    assert result == 3\n\n    result = candidate(label_image_2, label_image_1)\n    assert result == 1\n"}
{"task_id": "./human-eval-bia/measure_5.ipynb", "prompt": "def count_number_of_touching_neighbors(label_image):\n    \"\"\"\n    Takes a label image and returns a list of number of touching neighbors \n    for each labeled object.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import pyclesperanto_prototype as cle\n\n    touch_matrix = cle.generate_touch_matrix(label_image)\n    cle.set_row(touch_matrix, 0, 0)\n    cle.set_column(touch_matrix, 0, 0)\n\n    return np.asarray(cle.sum_y_projection(touch_matrix))[0,1:]", "entry_point": "count_number_of_touching_neighbors", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,0,0,0,0],\n        [0,0,2,2,0],\n        [0,0,1,3,0],\n        [0,4,1,0,0],\n        [0,0,0,0,0],\n    ])\n    print(candidate(label_image))\n    assert np.array_equal(candidate(label_image), [3, 2, 2, 1])"}
{"task_id": "./human-eval-bia/measure_6.ipynb", "prompt": "def measure_aspect_ratio_of_regions(label_image):\n    \"\"\"\n    Takes a label image and returns a pandas dataframe\n    with measurements for aspect_ratio of the objects\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import pandas as pd\n    stats = pd.DataFrame(skimage.measure.regionprops_table(label_image, properties=('minor_axis_length', 'major_axis_length')))\n    stats['aspect_ratio'] = stats['major_axis_length'] / stats['minor_axis_length']\n    return stats", "entry_point": "measure_aspect_ratio_of_regions", "test": "def check(candidate):\n    import numpy as np\n\n    label_image = np.asarray([\n        [0,1,1,0,0,3,3],\n        [0,1,1,0,0,3,3],\n        [0,2,2,2,2,3,3],\n        [0,2,2,2,2,3,3],\n        [0,4,4,4,0,3,3],\n        [0,4,4,4,0,3,3],\n        [0,4,4,4,0,0,0],\n    ])\n    \n    result = candidate(label_image) \n    print(result['aspect_ratio'])\n    assert np.allclose(result['aspect_ratio'], [1,2,3,1], atol=0.5)\n"}
{"task_id": "./human-eval-bia/measure_7.ipynb", "prompt": "def measure_intensity_over_time(image_list):\n    \"\"\"\n    Takes a timelapse (list of images), measures the average intensity over time and returns the resulting measurements as list.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image_list).mean(axis=(1,2))", "entry_point": "measure_intensity_over_time", "test": "def check(candidate):\n    import numpy as np\n\n    images = [\n        np.asarray([[0,1],[1,1]]),\n        np.asarray([[0,2],[2,2]]),\n        np.asarray([[0,3],[3,3]]),\n        np.asarray([[0,3],[2,2]]),\n        np.asarray([[0,2],[2,1]]),\n        np.asarray([[0,1],[1,0]]),\n    ]\n    reference = [0.75, 1.5, 2.25, 7/4, 5/4, 0.5]\n    \n    result = candidate(images) \n\n    assert np.allclose(reference, result, atol=0.001)\n"}
{"task_id": "./human-eval-bia/project_0.ipynb", "prompt": "def maximum_intensity_projection(image):\n    \"\"\"\n    Performs a maximum intensity projection along the first axis of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).max(axis=0)", "entry_point": "maximum_intensity_projection", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray(\n        [0,4,0,0,3,0]\n    )\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "./human-eval-bia/project_1.ipynb", "prompt": "def sum_intensity_projection(image):\n    \"\"\"\n    Performs a maximum intensity projection along the first axis of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).sum(axis=0)", "entry_point": "sum_intensity_projection", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,3,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,6,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray(\n        [0,5,0,0,9,0]\n    )\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "./human-eval-bia/segmentation_0.ipynb", "prompt": "def label_binary_image_and_count_labels(binary_image):\n    \"\"\"\n    Consumes as input a binary image, applies connected component labeling to it, \n    counts the labeled objects and returns their count as single number.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    label_image = skimage.measure.label(binary_image)\n\n    return len(np.unique(label_image)) - 1", "entry_point": "label_binary_image_and_count_labels", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [1,0,0,0,0],\n        [0,0,0,1,0],\n    ])) == 3\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 1\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 0"}
{"task_id": "./human-eval-bia/segmentation_1.ipynb", "prompt": "def apply_otsu_threshold_and_count_postiive_pixels(image):\n    \"\"\"\n    Takes an image, applies Otsu's threshold method to it to create a binary image and \n    counts the positive pixels.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n\n    result = np.sum(binary_image)\n\n    return result", "entry_point": "apply_otsu_threshold_and_count_postiive_pixels", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,1,1,0,0],\n        [1,1,1,0,0],\n        [1,0,0,0,0],\n        [0,0,0,1,0],\n    ])) == 8\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [1,2,1,0,0],\n        [0,1,3,4,0],\n        [0,1,4,1,0],\n    ])) == 4\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ])) == 0"}
{"task_id": "./human-eval-bia/segmentation_2.ipynb", "prompt": "def region_growing_segmentation(image, point):\n    \"\"\"\n    Segments an image using the region-growing/flood filling \n    starting from a single point.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    return skimage.segmentation.flood(image, point)", "entry_point": "region_growing_segmentation", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n    ]), (5,5)) \n\n    assert result.sum() * 1 == 16\n    assert result.min() == 0\n    assert result.max() == 1"}
{"task_id": "./human-eval-bia/statistics_0.ipynb", "prompt": "def t_test(dataframe, column1:str, column2:str):\n    \"\"\"\n    Takes two specified columns from a given dataframe and applies a paired T-test to it to determine the p-value.\n    \"\"\"", "canonical_solution": "\n    import scipy\n    data1 = dataframe[column1]\n    data2 = dataframe[column2]\n    return scipy.stats.ttest_rel(data1, data2)[1]\n    ", "entry_point": "t_test", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n    \n    result = candidate(df, \"a\",\"b\")\n    assert 6e-8 > result > 5e-8\n\n    result = candidate(df, \"a\",\"c\")\n    assert 0.4 > result > 0.3\n"}
{"task_id": "./human-eval-bia/statistics_1.ipynb", "prompt": "def mean_squared_error(image1, image2):\n    \"\"\"\n    Computes the mean-squared-error of two images compared pixel-by-pixel\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    image1 = np.asarray(image1)\n    image2 = np.asarray(image2)\n    return ((image1 - image2)**2).mean()\n    # adapted from : https://stackoverflow.com/questions/16774849/mean-squared-error-in-numpy", "entry_point": "mean_squared_error", "test": "def check(candidate):\n    image1 = [\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,2,0],\n        [0,0,0,0,0],\n    ]\n    image2 = [\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,2,0],\n        [0,0,0,0,0],\n    ]\n\n    mse = candidate(image1,image2)\n    print(mse)\n    assert mse == 0\n\n    image3 = [\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n        [0,0,0,0,0],\n    ]\n\n    mse = candidate(image1,image3)\n    print(mse)\n    assert mse == 5 / 25\n    \n"}
{"task_id": "./human-eval-bia/statistics_2.ipynb", "prompt": "def mean_std_column(dataframe, column:str):\n    \"\"\"\n    Computes the mean average and standard deviation of a specified column \n    in a given dataframe and returns these two values.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    data = dataframe[column]\n    return np.mean(data), np.std(data)", "entry_point": "mean_std_column", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n    \n    result_mean, result_std = candidate(df, \"a\")\n    assert abs(result_mean - 3.938) < 0.001\n    assert abs(result_std - 1.170) < 0.001\n\n\n    result_mean, result_std = candidate(df, \"b\")\n    assert abs(result_mean - 0.415) < 0.001\n    assert abs(result_std - 0.151) < 0.001\n\n    result_mean, result_std = candidate(df, \"c\")\n    assert abs(result_mean - 3.931) < 0.001\n    assert abs(result_std - 1.160) < 0.001\n\n    result_mean, result_std = candidate(df, \"d\")\n    assert abs(result_mean - 3.946) < 0.001\n    assert abs(result_std - 1.168) < 0.001\n"}
{"task_id": "./human-eval-bia/statistics_3.ipynb", "prompt": "def create_umap(dataframe):\n    \"\"\"\n    Takes a dataframe and computes a UMAP from all columns. \n    The two UMAP vectors are stored in the dataframe as `umap0` and `umap1`.\n    \"\"\"", "canonical_solution": "\n    import umap\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    # no return value", "entry_point": "create_umap", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n    candidate(df)\n    \n    expected_columns = ['umap0', 'umap1']\n\n    # I'm not sure how to check if the umap columns contain a proper umap, \n    # but we can check if all expected columns exist.\n    for ec in expected_columns:\n        assert ec in df.columns"}
{"task_id": "./human-eval-bia/statistics_4.ipynb", "prompt": "def pair_wise_correlation_matrix(dataframe):\n    \"\"\"\n    Takes a pandas dataframe and computes for all columns their Pearson's correlation coefficient\n    for all columns in the dataframe. For n columns, this is a n x n matrix of coefficients.\n    The matrix is returned as dataframe.\n    \"\"\"", "canonical_solution": "\n    return dataframe.corr()", "entry_point": "pair_wise_correlation_matrix", "test": "def check(candidate):\n    import pandas as pd\n    df = pd.DataFrame(\n        {\n         \"a\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.5], \n         \"b\":[0.1,0.2,0.3,0.3,0.4,0.4,0.4,0.5,0.5,0.5,0.6,0.6,0.6],\n         \"c\":[1.6,2.3,2.6,3.7,3.4,3.9,4.3,4.3,4.0,5.1,5.2,5.3,5.4],\n         \"d\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6],\n         \"e\":[1.7,2.4,2.4,3.6,3.5,3.9,4.4,4.2,4.1,5.0,5.1,5.4,5.6]\n        }\n    )\n\n    result = candidate(df)\n\n    print(result)\n\n    assert 'a' in result.columns\n    assert 'b' in result.columns\n    assert 'c' in result.columns\n    assert 'd' in result.columns\n    assert 'e' in result.columns\n\n    assert abs(result['a'].iloc[0] - 1) < 0.0001\n    assert abs(result['b'].iloc[1] - 1) < 0.0001\n    assert abs(result['c'].iloc[2] - 1) < 0.0001\n    assert abs(result['d'].iloc[3] - 1) < 0.0001\n    assert abs(result['e'].iloc[4] - 1) < 0.0001\n\n    # columns d and e are identical\n    assert abs(result['e'].iloc[3] - 1) < 0.0001\n    \n    assert result.size == 25"}
{"task_id": "./human-eval-bia/surfaces_0.ipynb", "prompt": "def extract_surface_measure_area(binary_volume_image):\n    \"\"\"\n    Take a 3D binary_volume_image, extracts the surface of the white (voxel value != 0) object \n    and returns the surface area of the object.\n    \"\"\"", "canonical_solution": "\n    import vedo\n    volume = vedo.Volume(binary_volume_image)\n    iso_surface = volume.isosurface()\n    return iso_surface.area()", "entry_point": "extract_surface_measure_area", "test": "def check(candidate):\n    import numpy as np\n    binary_volume_image = np.asarray([\n        [\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n        ],[\n            [0,0,0,0],\n            [0,1,1,0],\n            [0,1,1,0],\n            [0,0,0,0],\n        ],[\n            [0,0,0,0],\n            [0,1,1,0],\n            [0,1,1,0],\n            [0,0,0,0],\n        ],[\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n            [0,0,0,0],\n        ],\n    ])\n    assert abs(candidate(binary_volume_image) - 20) < 1\n\n    binary_volume_image = np.zeros((3,3,3))\n    binary_volume_image[1,1,1] = 1\n    assert abs(candidate(binary_volume_image) - 3) < 1\n"}
{"task_id": "./human-eval-bia/surfaces_1.ipynb", "prompt": "def convex_hull_measure_area(point_cloud):\n    \"\"\"\n    Take a 3D point_cloud, determines the convex hull around the points and returns the surface area of the convex hull.\n    \"\"\"", "canonical_solution": "\n    import vedo\n    convex_hull = vedo.shapes.ConvexHull(point_cloud)\n    return convex_hull.area()", "entry_point": "convex_hull_measure_area", "test": "def check(candidate):\n    point_cloud = [[0,1,0],[0,1,1],[0,0,0],[0,0,1],[1,1,0],[1,1,1],[1,0,0],[1,0,1]]\n\n    assert abs(candidate(point_cloud) - 6) < 0.001\n\n    point_cloud = [[0,1,0],[0,1,1],[0,0,0],[0,0,1],[2,1,0],[2,1,1],[2,0,0],[2,0,1]]\n\n    assert abs(candidate(point_cloud) - 10) < 0.001\n"}
{"task_id": "./human-eval-bia/transform_0.ipynb", "prompt": "def crop_quarter_image(image):\n    \"\"\"\n    Crops out the first half image in both dimensions (width and height). \n    The resulting image will be of quarter size compared to the original image.\n    \"\"\"", "canonical_solution": "\n    width = image.shape[1]\n    height = image.shape[0]\n\n    return image[:int(width/2),:int(height/2)]", "entry_point": "crop_quarter_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0],\n        [0,1,0],\n        [0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "./human-eval-bia/transform_1.ipynb", "prompt": "def transpose_image_axes(image):\n    \"\"\"\n    Transposes the first two axes of an image.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    return np.asarray(image).T", "entry_point": "transpose_image_axes", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,4,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,2,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "./human-eval-bia/transform_2.ipynb", "prompt": "def rotate_image_by_90_degrees(image):\n    \"\"\"\n    Rotates an image by 90 degrees clockwise around the center of the image.\n    \"\"\"", "canonical_solution": "\n    import pyclesperanto_prototype as cle\n    return cle.rotate(image, angle_around_z_in_degrees=90)", "entry_point": "rotate_image_by_90_degrees", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [0,0,0,0,0,0],\n        [0,1,0,0,2,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,4,0,0,3,0],\n        [0,0,0,0,0,0],\n    ])\n\n    reference = np.asarray([\n        [0,0,0,0,0,0],\n        [0,4,0,0,1,0],\n        [0,0,0,0,0,0],\n        [0,0,0,0,0,0],\n        [0,3,0,0,2,0],\n        [0,0,0,0,0,0],\n    ])\n    \n    assert np.array_equal(candidate(image), reference)\n"}
{"task_id": "./human-eval-bia/transform_3.ipynb", "prompt": "def subsample_image(image, n:int=2):\n    \"\"\"\n    Subsamples an image by skipping every n'th pixel in X and Y.\n    \"\"\"", "canonical_solution": "\n    return image[::n,::n]", "entry_point": "subsample_image", "test": "def check(candidate):\n    import numpy as np\n\n    image = np.asarray([\n        [1,2,3,4,5,6],\n        [7,8,9,0,1,2],\n        [3,4,5,6,7,8],\n        [9,0,1,2,3,4],\n        [5,6,7,8,9,0],\n        [1,2,3,4,5,6],\n    ])\n\n    reference = np.asarray([\n        [1,3,5],\n        [3,5,7],\n        [5,7,9],\n    ])\n    \n    assert np.array_equal(candidate(image, n=2), reference)\n\n    reference = np.asarray([\n        [1,4],\n        [9,2],\n    ])\n\n    assert np.array_equal(candidate(image, n=3), reference)"}
{"task_id": "./human-eval-bia/transform_4.ipynb", "prompt": "def rgb_to_grey_image_transform(rgb_image, r:float, g:float, b:float):\n    \"\"\"\n    Convert an RGB image to a single-channel gray scale image with \n    configurable weights r, g and b.\n    The weights are normalized to be 1 in sum.\n    \"\"\"", "canonical_solution": "\n    rgb_sum = r + g + b\n    r = r / rgb_sum\n    g = g / rgb_sum\n    b = b / rgb_sum\n    \n    import numpy as np\n    channel_r = np.asarray(rgb_image)[...,0]\n    channel_g = np.asarray(rgb_image)[...,1]\n    channel_b = np.asarray(rgb_image)[...,2]\n    grey_image = channel_r * r + \\\n                 channel_g * g + \\\n                 channel_b * b\n    \n    return grey_image", "entry_point": "rgb_to_grey_image_transform", "test": "def check(candidate):\n    import numpy as np\n    assert np.allclose(candidate([[[0,1,2], [3,3,3]]], 0.5, 0.25, 0.25),\n                                     [[0.75,  3]], atol=0.0001)\n\n    assert np.allclose(candidate([[[0,1,2], [3,3,3]]], 1, 2, 2),\n                                     [[1.2,  3]], atol=0.0001)\n                          "}
{"task_id": "./human-eval-bia/workflow_0.ipynb", "prompt": "def worflow_segmentation_measurement_summary(image):\n    \"\"\"\n    This function implements a workflow consisting of these steps:\n    * threshold intensity input image using Otsu's method\n    * label connected components\n    * measure area of the labeled objects\n    * determine mean area of all objects\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    binary_image = image > skimage.filters.threshold_otsu(image)\n    label_image = skimage.measure.label(binary_image)\n    stats = skimage.measure.regionprops(label_image)\n    areas = [s.area for s in stats]\n    return np.mean(areas)", "entry_point": "worflow_segmentation_measurement_summary", "test": "def check(candidate):\n    import numpy as np\n    \n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [1,1,1,0,0],\n        [1,1,1,0,0],\n        [1,1,0,0,0],\n        [0,0,0,0,0],\n    ])) == 8\n\n    assert candidate(np.asarray([\n        [1,1,0,1,1],\n        [1,1,0,0,0],\n        [0,0,0,1,1],\n        [1,1,0,1,1],\n        [0,0,0,0,0],\n    ])) == 3\n\n    assert candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,1,0],\n        [0,0,0,0,0],\n        [0,0,1,0,0],\n        [0,0,0,0,0],\n    ])) == 1"}
{"task_id": "./human-eval-bia/workflow_1.ipynb", "prompt": "def worflow_watershed_segmentation_correction_measurement(image):\n    \"\"\"\n    This function implements a workflow consisting of these steps:\n    * blurs the image a bit\n    * detect local minima in the blurred image\n    * apply watershed segmentation flooding the blurred image from the \n      detected minima to retrieve a label image\n    * remove all objects which touch the image border\n    * measure the area of all remaining objects together\n    \"\"\"", "canonical_solution": "\n    import skimage\n    blurred = skimage.filters.gaussian(image, sigma=1)\n    minima = skimage.morphology.local_minima(blurred)\n    spots = skimage.measure.label(minima)\n    labels = skimage.segmentation.watershed(blurred, spots)\n    labels_without_border = skimage.segmentation.clear_border(labels)   \n    binary = labels_without_border > 0\n    return binary.sum()", "entry_point": "worflow_watershed_segmentation_correction_measurement", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n        [1,1,1,1,1,1,1,1,1,1],\n        [0,0,1,0,0,0,0,1,0,0],\n        [0,0,1,0,0,0,0,1,0,0],\n    ])) \n\n    # if only the 4x4 pixels are segmented:\n    assert result >= 16\n    # if it also considers borders as part of the center object:\n    assert result <= 36 \n"}
{"task_id": "./human-eval-bia/workflow_2.ipynb", "prompt": "def worflow_segmentation_counting(image):\n    \"\"\"\n    This function segments objects in an image with intensity above average \n    and returns their count.\n    \"\"\"", "canonical_solution": "\n    import skimage\n    import numpy as np\n    average_intensity = np.asarray(image).mean()\n    binary = image > average_intensity\n    labels = skimage.measure.label(binary)\n    return labels.max()", "entry_point": "worflow_segmentation_counting", "test": "def check(candidate):\n    import numpy as np\n    \n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,1,0,0,0],\n        [0,0,0,2,0],\n        [0,1,0,0,0],\n        [0,0,0,0,0],\n    ])) \n    assert result == 3\n\n    result = candidate(np.asarray([\n        [0,0,0,0,0],\n        [0,100,0,90,0],\n        [0,0,0,0,0],\n        [0,110,0,80,0],\n        [0,0,0,0,0],\n    ])) \n    assert result == 4"}
{"task_id": "./human-eval-bia/workflow_3.ipynb", "prompt": "def count_objects_over_time(binary_image_list):\n    \"\"\"\n    Takes a timelapse (list of binary images), counts the number of connected components and returns the resulting counts as list.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    from skimage.measure import label\n    labels = [label(binary_image) for binary_image in binary_image_list]\n    return [len(np.unique(label)) - 1 for label in labels]", "entry_point": "count_objects_over_time", "test": "def check(candidate):\n    import numpy as np\n\n    images = [\n        np.asarray([\n            [1,0,0,0],    \n            [0,0,0,0],    \n            [0,0,1,0],    \n            [0,0,0,0],            \n        ]),\n        np.asarray([\n            [1,0,0,0],    \n            [0,0,0,0],    \n            [0,0,1,1],    \n            [0,0,0,0],            \n        ]),\n        np.asarray([\n            [1,0,0,0],    \n            [0,0,0,0],    \n            [0,0,0,1],    \n            [0,1,0,0],            \n        ]),\n        np.asarray([\n            [1,1,0,0],    \n            [0,0,0,0],    \n            [0,0,0,1],    \n            [0,1,0,0],            \n        ]),\n        np.asarray([\n            [0,0,1,0],    \n            [1,0,0,0],    \n            [0,0,0,1],    \n            [0,1,0,0],            \n        ]),\n    ]\n    reference = [2,2,3,3,4]\n    \n    result = candidate(images) \n\n    assert np.allclose(reference, result)\n"}
{"task_id": "./human-eval-bia/workflow_4.ipynb", "prompt": "def segment_measure_umap(image):\n    \"\"\"\n    This function takes a single channel intensity image, \n    segments objects with intensity above half the maximum intensity, \n    labels connected components, \n    measures area, perimeter, mean_intensity, minor and major axis of the labeled objects, \n    and produces a UMAP from the given measurements. \n    The two UMAP vectors are saved as `umap0` and `umap1` togther with the measurements in a dataframe. \n    The function returns this dataframe.\n    \"\"\"", "canonical_solution": "\n    import numpy as np\n    import pandas as pd\n    import umap\n    from skimage.measure import label, regionprops_table\n\n    image = np.asarray(image)\n\n    # segment\n    binary = image > 0.5 * image.max()\n    labels = label(binary)\n\n    # measure\n    dataframe = pd.DataFrame(regionprops_table(labels, intensity_image=image, \n                                              properties=['area', 'perimeter', 'mean_intensity', \n                                                          'minor_axis_length', 'major_axis_length']))\n\n    # append UMAP\n    embedding = umap.UMAP().fit_transform(dataframe)\n    dataframe['umap0'] = embedding[:,0]\n    dataframe['umap1'] = embedding[:,1]\n\n    return dataframe", "entry_point": "segment_measure_umap", "test": "def check(candidate):\n    import numpy as np\n\n    images = np.asarray([\n            [1,0,0,0,1,0,1,1,0,0],    \n            [1,0,1,0,0,0,0,0,0,0],    \n            [1,0,0,0,1,0,1,0,1,0],    \n            [1,0,1,0,0,0,0,0,1,0],    \n            [1,0,0,0,0,0,0,0,0,0],    \n            [1,0,0,1,0,1,1,0,1,0],    \n            [1,0,0,1,0,1,0,0,1,0],    \n            [1,0,0,1,0,0,0,1,1,0],    \n            [1,0,0,0,0,1,0,0,0,0],    \n            [1,0,1,0,0,0,0,0,0,0],    \n        ])\n    \n    result = candidate(images) \n\n    expected_columns = ['area', 'perimeter', 'mean_intensity', \n                        'minor_axis_length', 'major_axis_length',\n                        'umap0', 'umap1']\n\n    # I'm not sure how to check if the umap columns contain a proper umap, \n    # but we can check if all expected columns exist.\n    for ec in expected_columns:\n        assert ec in result.columns"}
